Basis
    - A set B = {u1, u2,....,um} is a basis for subspace S if B spans S and B is linearly independent

Subspace - if satisfies following conditions
    1) S contains 0, with zero vector
    2) (Closed under addition) If u and v are in S, the u + s is also in S
    3) (Closed under multiplication) If r is a real number and u is in S, then ru is also in S

Codomain (Output Vector)
    - A set containing *ALL POSSIBLE* output for a function,
    (note that this contains the *range* which is equal to the set of possible output for a function)

Domain (Input Vector)
    - The set of possible inputs for a function
        (T is one to one if every vector in domain of T is sent to its "Own" unique vector in the range)

Range
    - The set of output for a function = set of all vectors y such that T(x) = y
    - range(T) = range of T = image of T 
    - Subspace of codomain in R^n
    Col(A)

Dimension(Subspace) - Let S be a non-zero Subspace. Then the dimension of S is number of vectors in any basis of S.

Kernel
    - Given a linear transformation T, the set of all vectors x such that T(x) = 0 is the kernel of T, Ker(T) and is subspace 
      of the domain of T. And is Subspace of R^m
    - Ax = T(x) 
    - Ker(T) = Null(A)

Null Space
    - If A is an n*m matrix, then the set of solutions Ax = 0 is called null space of A, null(A)
    - Subspace of R^m

Nullity
    - If A is an n*m matrix, then the nullity of A , Nullity(A), is dimension of null(A)
    - dim(Null(A)) = # of free variables

Rank
    - Dimension of row spaces or dimension of column space
    - # of pivot points
    - dim(row(A)) = dim(col(A))

Rank Nullity theoreom
    - Given n * m Matrix A
    - Rank(A) + Nullity(A) = m

echelon form
    A rectangular matrix is in row echelon form if it has the following three properties:
        - All nonzero rows are above any rows of all zeros
        - Each leading entry of a row is in a column to the right of the leading entry of the row above it
        - All entries of a column below a leading entry are zeros

Reduced Echelon form
     a matrix in echelon form satisfies the following conditions, then it is in reduced row echelon form:
        - The matrix is in row-echelon form
        - Each leading 1 is the only nonzero entry in its column

Inner Product
    Consider the vector space V,
    Let u,v,w ∈ V 
    An inner product <u,v> is a function that maps u,v ->scalar
    this has following properties
    1) <u,v> = <v,u> (Symmetric)
    2) <cu,v> = c<u,v>             c is a constant
    3) <u+w,v> = <u,v> + <w,v>
    4) <u,u> >= 0 (Positive Definite)
        -> if <u,u> = 0 then u = 0
eg)
    <au + bw, v> = a<u,v> + b<w,v>
    <v,au + bw> =  a<u,v> + b<w,v>

Binary mapping
    - <u,v> = <v,u> 이런것을 symmetric 이라고 부름

Dot product
    - dot product refers to the product ∑aibi for two vectors  a,b∈R^n

Distance & Metric (V, <-,->), for x,y ∈ V
    - d(x,y) = ||x-y|| = sqrt( <x-y, x-y> )   --> (Distance between x and y)
    
    이거 수정 해야함 밑에
    e.g
    <x,y> = x^T * y => d(x,y)  => Euclidean Distance
    Mapping d: V*V -> R
            (x,y) -> d(x,y) --> no innder product involved
            is called Metric

Angles and Orthgonality


orthonormal이라는 말은 orthogonal과 normal이 합쳐진 말로서 두 벡터 v1, v2가 모두 단위벡터(unit vector)이면서 
서로 수직이면 두 벡터 v1, v2는 orthonormal(정규직교)하다고 한다

Orthgonal
    - In elementary geometry, orthogonal is the same as perpendicular. 
      Two lines or curves are orthogonal if they are perpendicular at their point of intersection.
      Two vectors and of the real plane or the real space are orthogonal iff their dot product v·w=0
    - More generally, two elements v and w of an inner product space E are called orthogonal if the inner product of v and w is 0.
      Two subspaces V and W of E are called orthogonal if every element of V is orthogonal to every element of W. 
      The same definitions can be applied to any symmetric or differential k-form and to any Hermitian form.

    Orthgonal 정리
        - orthogonal if the inner product of v and w is 0.
        eg)
            x = [1      y = [-1
                 1]           1]
            <x,y> = x^T * y = 0
        ==> [1,1][-1     => 1*-1 + 1*1 = -1 + 1 = 0 ==> orthogonal -> perpendicular
                   1]

Orthogonal matrix
    - A  ∈ n*n orthogonal iff columns of A are orthonormal so that A^T * A = I = AA^T
    -> A^-1 (inverse) = A^T (Transpose)



Cauchy-Schwarz inequality
    - |<x,y>| <= ||x||*||y||
    -> |<x,y>| / ||x||*||y||  <= 1

    cos w = <x,y> / ||x||*||y||   for some w = [o, pi]
    --> ||x||*||y|| * cos w = <x,y> = x^T * y      (x^T = x transpose)

Norm
     ||x|| = sqrt(<x,x)) = sqrt(x^T * x)
        note (<x,x> = x^T * y)
Orthonormal basis

    - A subset {v_1,...,v_k} of a vector space V, with the inner product <,>, is called orthonormal if <v_i,v_j>=0 when i!=j.
    - That is, the vectors are mutually perpendicular. Moreover, they are all required to have length one: <v_i,v_i>=1.
    - An orthonormal set must be linearly independent, and so it is a vector basis for the space it spans. Such a basis is called an orthonormal basis.


    - In mathematics, particularly linear algebra, an orthonormal basis for an inner product space V with finite dimension is a basis
      for V whose vectors are orthonormal, that is, they are all unit vectors and orthogonal to each other.[1][2][3].
      For example, the standard basis for a Euclidean space Rn is an orthonormal basis, where the relevant inner product 
      is the dot product of vectors. The image of the standard basis under a rotation or reflection (or any orthogonal transformation)
       is also orthonormal, and every orthonormal basis for Rn arises in this fashion.


Orthogonal Projection
    An Orthogonal Projection is a decomposition of a vector into the sum of two orthogonal(perpendicular) vectors
In an orthogonal projection, any vector v can be written v=v_W+v_W(ㅗ), so

 <v,Pw>=<v_W,Pw>=<Pv,w>, 
and the projection matrix is a symmetric matrix iff the vector space projection is orthogonal.

    Practice
    Ley y  = [7      u = [2
              6]          1]          Find the orthogonal projection
    
    Step 1 Determin the projection of
        - y projection = (y * u )/ (u*u) * u

        -> 14 + 6
         --------- [2     = > 20/5 [2     ==> 4 [2    =   [8      = yㅗ
           4 + 1    1]              1]           1]        4]

    Step 2 Determine the component of y orthogonal to u (projection), y - y projection
    y - yㅗ = [-1
                2]
    yㅗ = [8
           4]
    
    step 3 Verify y, y-yㅗ is orthognonal set
    <y,y-yㅗ>  = 0
    8(-1) + 4(2)  = -8 + 8 = 0
    Correct

Properties of inner product
    1) bilinear
    2) positive difinitive
    3) symmetric

1) bilinear
    <au + bv, y> = a<u,y> + b<v,y> so blah is bilinear
2) Positive difinitive
    show
    if x = 0 ==> <x,x> = 0
    if x != 0 ==> <x,x> > 0
3) symmetric
    show <y,x> = <x,y>