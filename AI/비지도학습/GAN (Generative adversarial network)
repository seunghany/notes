비지도학습의 가장 대표적인 선두주자로는 Generative adversarial network (GAN)

비지도학습 GAN은 원 데이터가 가지고 있는 확률분포를 추정하도록 하고,
인공신경망이 그 분포를 만들어 낼 수 있도록 한다는 점에서 단순한 군집화 기반의 비지도학습과 차이가 있습니다.

GAN 이해 하기 위해서는 확률분포의 개념을 알고 넘어가야 함
GAN의 다루고자 하는 모든 데이터는 확률분포를 가지고 있는 랜덤변수(Random Variable) 이기 때문
e.g 2차 방정식 미지 수 X를 변수라 부르고, 이를 대입해 방정식을 풀면 미지수 X는 특정한 수가 됩니다.
그러나, 랜덤변수는 측정할 때마다 다른 값이 나옵니다.
하지만, 특정한 활률분포를 따르는 숫자를 생성하므로,
랜덤변수에 대한 확률분포를 안다는 이야기는 랜덤변수 즉 데이터에 대한 전부를 이해하고 있다는 것과 같습니다.

e.g



GAN의 한계
1. 생성자와 분류자가 대결하며 학습하는 구도인 만큼 학습이 불안정
    -> 생성자와 분류자가 서로 균형 있게 훈련 주고 받는데, 두 모델 간 실력차가 발생하는 경우
       훈련이 한쪽에 치우쳐 성능이 제약됨
    -> GAN의 훈련 성능을 높이기 위한 다양한 연구를 진행되고 있는데, 대표적인 것이 DCGAN(Deep Convolutional GAN)

DCGAN
DCGAN은 GAN에 지도학습에서 이미 폭넓게 적용되던 CNN을 사용되는 것으로,
비지도학습 적용을 위해 기존의 fully connected DNN 대신 CNN(Convolution Neural Networks) 기법으로 신경망 구성.

CNN
CNN은 전체 데이터의 특정 부분에 대한 주요 특징 값을 추출하는 Convolution layer(필터 효과)와 추출한 특징 중 제일 중요한 값만
추려내는 Pooling layer가 교차하면서 이루어집니다. 이때 이미지와 같은 부분의 특징을 읽어내는 성능이 탁월하여 학습이 잘 된다는 장점을
GAN의 이미지 생성에 적용한 것입니다. 또한, 각 층 해당 뉴런의 입력 대비 출력을 얼마나 반영할지 결정하는 함수인 활성화함수(Activation function)
의 적절한 선택이 중요한데, GAN을 위해서 leaky_ReLU를 사용하여 분류자의 학습 효율을 높였습니다.
-> GAN이 가진 문제점 상당 부분 극복


